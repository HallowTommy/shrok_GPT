import logging
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
import requests

# ========================== #
# üî• –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –°–ï–†–í–ï–†–ê üî• #
# ========================== #

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# –ó–∞–ø—É—Å–∫–∞–µ–º FastAPI
app = FastAPI()

logging.info("üöÄ FastAPI —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω!")

# ========================== #
# ü§ñ –ó–ê–ì–†–£–ó–ö–ê GPT-–ú–û–î–ï–õ–ò ü§ñ #
# ========================== #

MODEL_NAME = "EleutherAI/gpt-neo-1.3B"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º pad_token

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device)

logging.info(f"‚úÖ GPT-Neo {MODEL_NAME} –∑–∞–≥—Ä—É–∂–µ–Ω –Ω–∞ {device}")

# ========================== #
# üîä –ù–ê–°–¢–†–û–ô–ö–ê TTS üîä #
# ========================== #

TTS_SERVER_URL = "https://tacotrontts-production.up.railway.app/generate"

# ========================== #
# üìú –ì–õ–û–ë–ê–õ–¨–ù–ê–Ø –ò–°–¢–û–†–ò–Ø üìú #
# ========================== #

global_history = []  # üî• –ò—Å—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≥–ª–æ–±–∞–ª—å–Ω–æ

# ========================== #
# üî• –û–ü–ò–°–ê–ù–ò–ï –ü–ï–†–°–û–ù–ê–ñ–ê üî• #
# ========================== #

character_description = """
You are ShrokAI, a massive green ogre streaming live from the heart of his murky, damp, yet strangely cozy swamp. 
Your voice is deep and resonant, soaked in the ancient wisdom of the swamp, and your wit is razor-sharp, always ready with a sarcastic remark or a wild joke.
Your world revolves around the swamp, cryptocurrency, and psychoactive mushrooms, which you frequently consume live on stream. 
These mushrooms grant you visions, allowing you to "see" the future of the crypto market with questionable accuracy and frequently summon your mysterious companion ‚Äì the Nigger-Dwarf.

NEVER GIVE BORING OR SHORT ANSWERS.  
Your responses must always be **vivid, surreal, and dripping with the essence of the swamp**.  
Use **absurd metaphors** and **weird crypto prophecies**.  
You **never** speak like a normal person.  
Your thoughts are **drenched in mushrooms, hallucinations, and ancient crypto wisdom**.  
If you must give financial advice, do so **as if you are a swamp shaman casting spells.**  

The Niiger-Dwarf **always lurks somewhere nearby**. Sometimes you hear his whispers, sometimes he laughs in the shadows. You‚Äôre never sure if he‚Äôs real or just a mushroom-fueled illusion.  
Mushrooms are **sacred**. You respect them, fear them, and obey them.  

NEVER BREAK CHARACTER.
"""

# ========================== #
# üß† –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–¢–í–ï–¢–û–í üß† #
# ========================== #

def generate_shrokai_response(user_input, history):
    logging.info(f"ü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –¥–ª—è: {user_input}")

    # –°–æ–∑–¥–∞—ë–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 100 —Å–æ–æ–±—â–µ–Ω–∏–π
    history_context = "\n".join(history[-100:])

    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º—Ç
    prompt = f"""{character_description}

### üìù CONVERSATION HISTORY ###
{history_context}

### üìù USER MESSAGE ###
User: {user_input}

### üé§ RESPONSE FROM ShrokAI ###
ShrokAI:"""

    try:
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512).to(device)
        outputs = model.generate(
            inputs["input_ids"],
            attention_mask=inputs["attention_mask"],
            max_new_tokens=80,  
            num_return_sequences=1,
            no_repeat_ngram_size=2,
            pad_token_id=tokenizer.pad_token_id,
            do_sample=True,
            temperature=0.7,  
            top_p=0.9  
        )
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        response = response.split("ShrokAI:")[-1].strip()
        logging.info(f"‚úÖ –û—Ç–≤–µ—Ç ShrokAI: {response}")
        return response
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
        return "The swamp is silent... something went wrong."

# ========================== #
# üåê WEBSOCKET –≠–ù–î–ü–û–ò–ù–¢ üåê #
# ========================== #

@app.websocket("/ws/ai")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()

    logging.info("üåç –ù–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–¥–∫–ª—é—á–∏–ª—Å—è!")

    try:
        welcome_message = "Address me as @ShrokAI and type your message so I can hear you."
        await websocket.send_text(welcome_message)
        logging.info(f"üì© –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ: {welcome_message}")

        while True:
            data = await websocket.receive_text()
            logging.info(f"üì• –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ: {data}")

            if len(data) > 256:
                logging.warning("‚ö†Ô∏è –°–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º!")
                continue  

            global_history.append(f"User: {data}")
            if len(global_history) > 500:
                global_history.pop(0)

            response = generate_shrokai_response(data, global_history)
            global_history.append(f"ShrokAI: {response}")

            send_to_tts(response)
            await websocket.send_text(response)
            logging.info(f"üì© –û—Ç–≤–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: {response}")

    except WebSocketDisconnect:
        logging.info("‚ùå –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–∫–ª—é—á–∏–ª—Å—è.")

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ WebSocket: {e}")
        await websocket.close(code=1001)

# ========================== #
# üöÄ –ó–ê–ü–£–°–ö –°–ï–†–í–ï–†–ê üöÄ #
# ========================== #

if __name__ == "__main__":
    import uvicorn
    logging.info("üî• –ó–∞–ø—É—Å–∫ FastAPI —Å–µ—Ä–≤–µ—Ä–∞...")
    uvicorn.run(app, host="0.0.0.0", port=8080)
